
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.0">
    
    
      
        <title>HuBERT - Sapphire Lab</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.9f615399.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hubert" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Sapphire Lab" class="md-header__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sapphire Lab
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              HuBERT
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Sapphire Lab" class="md-nav__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sapphire Lab
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../../PDE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDE
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract: 摘要
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1introduction" class="md-nav__link">
    1.Introduction: 引言
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2related-works" class="md-nav__link">
    2.Related Works: 相关工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3methodology" class="md-nav__link">
    3.Methodology: 方法
  </a>
  
    <nav class="md-nav" aria-label="3.Methodology: 方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31learning-the-hidden-units-for-hubert" class="md-nav__link">
    3.1.Learning the Hidden Units for HuBERT
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32representation-learning-via-masked-prediction" class="md-nav__link">
    3.2.Representation Learning via Masked Prediction
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33learning-with-cluster-ensembles" class="md-nav__link">
    3.3.Learning with Cluster Ensembles
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34iterative-refinement-of-cluster-assignments" class="md-nav__link">
    3.4.Iterative Refinement of Cluster Assignments
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35implementation" class="md-nav__link">
    3.5.Implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4experiments" class="md-nav__link">
    4.Experiments: 实验
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5results" class="md-nav__link">
    5.Results: 结果
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6conclusions" class="md-nav__link">
    6.Conclusions: 结论
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="hubert">HuBERT<a class="headerlink" href="#hubert" title="Permanent link">&para;</a></h1>
<details>
<summary>基本信息</summary>

- 标题: HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units
- 作者:
  - 01 [Wei-Ning Hsu](../../Authors/Wei-Ning_Hsu.md)
  - 02 [Benjamin Bolte](../../Authors/Benjamin_Bolte.md)
  - 03 [Yao-Hung Hubert Tsai](../../Authors/Yao-Hung_Hubert_Tsai.md)
  - 04 [Kushal Lakhotia](../../Authors/Kushal_Lakhotia.md)
  - 05 [Ruslan Salakhutdinov](../../Authors/Ruslan_Salakhutdinov.md)
  - 06 [Abdelrahman Mohamed](../../Authors/Abdelrahman_Mohamed.md)
- 机构:
  - [Meta AI](../../Institutions/Meta.AI.md)
  - [卡内基梅隆大学](../../Institutions/CMU_美国卡内基梅隆大学.md)
- 时间:
  - 预印时间: 2021.06.14 ArXiv v1
  - 更新笔记: 2024.07.04
- 发表:
  - [TASLP](../../Publications/TASLP.md)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2106.07447)
  - [DOI](https://doi.org/10.1109/TASLP.2021.3122291)
  - [Github](https://github.com/facebookresearch/fairseq/tree/main/examples/hubert)
- 标签:
  - [自监督学习](../../Tags/Learning_Self-Supervised.md)
  - [语音表示](../../Tags/SpeechRepresentation.md)
  - [开源](../../Tags/OpenSource.md)
- 页数: 10
- 引用: 64
- 被引: 1776
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

<h2 id="abstract">Abstract: 摘要<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h2>
<details>
<summary>原文</summary>

> Self-supervised approaches for speech representation learning are challenged by three unique problems: 
> (1) there are multiple sound units in each input utterance, 
> (2) there is no lexicon of input sound units during the pre-training phase, 
> (3) sound units have variable lengths with no explicit segmentation. 
> 
> To deal with these three problems, we propose the ***Hidden-Unit BERT (HuBERT)*** approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. 
> A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. 
> ***HuBERT*** relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. 
> Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the ***HuBERT*** model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine-tuning subsets. 
> Using a 1B parameter model, ***HuBERT*** shows up to 19% and 13% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.
>  OpenSource: https://github.com/pytorch/fairseq/tree/master/examples/hubert

</details>
<p><br></p>
<p>用于语音表示学习的自监督方法面临三个独特的问题:
1. 每个输入发言中有多个声学单元;
2. 在预训练阶段没有输入声学单元的词典;
3. 声学单元具有可变长度, 没有明确的分割.</p>
<p>为了处理这三个问题, 本文提出了 <strong><em>Hidden-Unit BERT (HuBERT)</em></strong> 方法用于自监督语音表示学习, 它利用离线聚类步骤为 BERT 类预测损失提供对齐的目标标签.
这一方法的关键组件是只对掩膜区域应用预测损失, 使得模型能够在连续类型输入上学习一个声学和语言相结合的模型.
<strong><em>HuBERT</em></strong> 主要依赖于无监督聚类步骤的一致性, 而不是分配的聚类标签的内在质量.
以 100 个聚类教师开始, 使用两次聚类, <strong><em>HuBERT</em></strong> 模型可以匹配或超过 wav2vec 2.0 在 LibriSpeech (960h) 和 Libri-light (60,000h) 基准上分别进行 10min, 1h, 10h, 100h, 和 960h 微调子集的性能.
使用 1B 参数模型, <strong><em>HuBERT</em></strong> 展示了 19% 和 13% 的相对 WER 减少在更具挑战性的 dev-other 和 test-other 评估子集上.</p>
<h2 id="1introduction">1.Introduction: 引言<a class="headerlink" href="#1introduction" title="Permanent link">&para;</a></h2>
<h2 id="2related-works">2.Related Works: 相关工作<a class="headerlink" href="#2related-works" title="Permanent link">&para;</a></h2>
<blockquote>
<p>We discuss recent studies on self-supervised speech representation learning by grouping them by training objective.
The earliest line of work learns representations by postulating a generative model for speech with latent variables, which are assumed to capture the relevant phonetic information.
Training of these models amounts to likelihood maximization.
Different latent structures have been applied to encode the prior assumption, such as continuous [29], discrete [31], [42], or sequential [28], [30], [32], [33], [43].</p>
<p>Prediction-based self-supervised learning has gathered increasing interests recently, where a model is tasked to predict the content of the unseen regions [4], [44]–[50] or to contrast the target unseen frame with randomly sampled ones [1] [2] [3], [6].
Some models combine both the predictive and the contrastive losses [5], [51].
These objectives can usually be interpreted as mutual information maximization [52].
Other objectives do not belong to these categories, for example, [53].</p>
<p>This work is most related to DiscreteBERT [51]: both HuBERT and DiscreteBERT predict discrete targets of masked regions.
However, there are several crucial differences.
First, instead of taking quantized units as input, HuBERT takes raw waveforms as input to pass as much information as possible to the transformer layers, which was shown to be important in [6].
Furthermore, in the experiment section, we show that our model, with simple k-means targets, can achieve better performance than DiscreteBERT that uses vq-wav2vec [5] learned units.
Second, we also present many techniques to improve teacher quality instead of using a single fixed teacher as done in DiscreteBERT.</p>
<p>HuBERT is also related to wav2vec 2.0 [6].
However, the latter employs a contrastive loss that requires careful design of where to sample negative frames from, an auxiliary diversity loss to encourage the discrete unit usage, and demands a proper Gumbel-softmax temperature annealing schedule.
In addition, it only explores quantizing the waveform encoder output, which may not be the best feature for quantization due to the limited capacity of the convolutional encoder, as suggested by our ablation studies in Figure 2.
Concretely, our proposed method adopts a more direct predictive loss by separating the acoustic unit discovery step from the masked prediction representation learning phase and achieves the state-of-the-art results that match or outperform wav2vec 2.0 on different fine-tuning scales.</p>
<p>Finally, the idea of iterative refinement target labels is similar to iterative pseudo labeling for semi-supervised ASR [12], [54], which leverages an improving student model to generate better pseudo-labels for the next iteration of training.
The HuBERT approach can be seen as extending this method to the self-supervised setup with a masked prediction loss.</p>
</blockquote>
<h2 id="3methodology">3.Methodology: 方法<a class="headerlink" href="#3methodology" title="Permanent link">&para;</a></h2>
<h3 id="31learning-the-hidden-units-for-hubert">3.1.Learning the Hidden Units for HuBERT<a class="headerlink" href="#31learning-the-hidden-units-for-hubert" title="Permanent link">&para;</a></h3>
<h3 id="32representation-learning-via-masked-prediction">3.2.Representation Learning via Masked Prediction<a class="headerlink" href="#32representation-learning-via-masked-prediction" title="Permanent link">&para;</a></h3>
<h3 id="33learning-with-cluster-ensembles">3.3.Learning with Cluster Ensembles<a class="headerlink" href="#33learning-with-cluster-ensembles" title="Permanent link">&para;</a></h3>
<h3 id="34iterative-refinement-of-cluster-assignments">3.4.Iterative Refinement of Cluster Assignments<a class="headerlink" href="#34iterative-refinement-of-cluster-assignments" title="Permanent link">&para;</a></h3>
<h3 id="35implementation">3.5.Implementation<a class="headerlink" href="#35implementation" title="Permanent link">&para;</a></h3>
<h2 id="4experiments">4.Experiments: 实验<a class="headerlink" href="#4experiments" title="Permanent link">&para;</a></h2>
<h2 id="5results">5.Results: 结果<a class="headerlink" href="#5results" title="Permanent link">&para;</a></h2>
<h2 id="6conclusions">6.Conclusions: 结论<a class="headerlink" href="#6conclusions" title="Permanent link">&para;</a></h2>
<details>
<summary>原文</summary>

> This paper presents ***HuBERT***, a speech representation learning approach that relies on predicting K-means cluster assignments of masked segments of continuous input.
> On both the Librispeech 960 hours and the 60,000 hours Libri-light pre-training setups, ***HuBERT*** matches or outperforms the state-of-the-art systems over all fine-tuning subsets of 10mins, 1h, 10h, 100h, and 960h.
> Furthermore, the learned representation quality improves dramatically with iteratively refining K-means cluster assignments using learned latent representations for a previous iteration.
> Finally, ***HuBERT*** scales well to a 1B transformer model showing a relative reduction in WER of up to 13% on the test-other subset.
> For future work, we plan to improve the ***HuBERT*** training procedure to consist of a single phase.
> Furthermore, given the high quality of its representations, we will consider using ***HuBERT*** pre-trained representations for multiple downstream recognition and generation tasks beyond ASR.

</details>
<p><br></p>
<p>本文展示了 <strong><em>HuBERT</em></strong>, 一种依赖于预测掩膜片段的连续输入的 K-means 聚类分配的语音表示学习方法.
在 LibriSpeech 960 小时和 Libri-light 60,000 小时的预训练设置上, <strong><em>HuBERT</em></strong> 超过了所有微调子集的最新系统.
此外, 学习到的表示质量随着迭代式的修正 K-means 聚类分配而显著提高.
最后, <strong><em>HuBERT</em></strong> 适用于 1B 变压器模型, 显示了 WER 的相对减少在 test-other 子集上最多 13%.
为了未来的工作, 我们计划改进 <strong><em>HuBERT</em></strong> 训练过程, 使其包含单个阶段.
此外, 由于其高质量的表示, 我们将考虑使用 <strong><em>HuBERT</em></strong> 预训练表示来进行多任务的语音识别和生成.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.a264c092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4e0fa4ba.min.js"></script>
      
    
  </body>
</html>