
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.0">
    
    
      
        <title>HyperTTS - Sapphire Lab</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.9f615399.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hypertts" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Sapphire Lab" class="md-header__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sapphire Lab
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              HyperTTS
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Sapphire Lab" class="md-nav__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sapphire Lab
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../../PDE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDE
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1introduction" class="md-nav__link">
    1.Introduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2related-work" class="md-nav__link">
    2.Related Work
  </a>
  
    <nav class="md-nav" aria-label="2.Related Work">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#text-to-speech-models" class="md-nav__link">
    Text-to-Speech Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#speaker-adaptation-in-tts" class="md-nav__link">
    Speaker Adaptation in TTS
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dynamic-parameters" class="md-nav__link">
    Dynamic Parameters
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3methodology" class="md-nav__link">
    3.Methodology
  </a>
  
    <nav class="md-nav" aria-label="3.Methodology">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31encoder" class="md-nav__link">
    3.1.Encoder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32variance-adaptor" class="md-nav__link">
    3.2.Variance Adaptor
  </a>
  
    <nav class="md-nav" aria-label="3.2.Variance Adaptor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#duration-predictor" class="md-nav__link">
    Duration Predictor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pitch-predictor" class="md-nav__link">
    Pitch Predictor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#energy-predictor" class="md-nav__link">
    Energy Predictor
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33mel-decoder-and-postnet" class="md-nav__link">
    3.3.Mel-Decoder and Postnet
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34hypernetwork" class="md-nav__link">
    3.4.Hypernetwork
  </a>
  
    <nav class="md-nav" aria-label="3.4.Hypernetwork">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4experiments" class="md-nav__link">
    4.Experiments
  </a>
  
    <nav class="md-nav" aria-label="4.Experiments">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41baseline-models" class="md-nav__link">
    4.1.Baseline Models
  </a>
  
    <nav class="md-nav" aria-label="4.1.Baseline Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tts-0" class="md-nav__link">
    TTS-0
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reference-and-reference-voc" class="md-nav__link">
    Reference and Reference (Voc.)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tts-ft-full-fine-tuning" class="md-nav__link">
    TTS-FT (Full Fine-Tuning)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adaptertts" class="md-nav__link">
    AdapterTTS
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hypertts_1" class="md-nav__link">
    HyperTTS
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42datasets" class="md-nav__link">
    4.2.Datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43model-configuration" class="md-nav__link">
    4.3.Model Configuration
  </a>
  
    <nav class="md-nav" aria-label="4.3.Model Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backbone-model-pre-training" class="md-nav__link">
    Backbone Model Pre-training
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44evaluation-metrics" class="md-nav__link">
    4.4.Evaluation Metrics
  </a>
  
    <nav class="md-nav" aria-label="4.4.Evaluation Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#objective-metrics" class="md-nav__link">
    Objective Metrics
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#subjective-metrics" class="md-nav__link">
    Subjective Metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5results-discussions" class="md-nav__link">
    5.Results &amp; Discussions
  </a>
  
    <nav class="md-nav" aria-label="5.Results & Discussions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51subjective-evaluation" class="md-nav__link">
    5.1.Subjective Evaluation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52impact-of-parameter-efficiency" class="md-nav__link">
    5.2.Impact of Parameter Efficiency
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53output-of-hypernetwork" class="md-nav__link">
    5.3.Output of Hypernetwork
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54other-discussions" class="md-nav__link">
    5.4.Other Discussions
  </a>
  
    <nav class="md-nav" aria-label="5.4.Other Discussions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#layernorms-standard-conditional" class="md-nav__link">
    Layernorms (Standard &amp; Conditional)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#low-rank-adaptation" class="md-nav__link">
    Low-Rank Adaptation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6conclusion" class="md-nav__link">
    6.Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="hypertts">HyperTTS<a class="headerlink" href="#hypertts" title="Permanent link">&para;</a></h1>
<details>
<summary>基本信息</summary>

- 标题: HyperTTS: Parameter Efficient Adaptation in Text-to-Speech Using Hypernetworks
- 作者:
  - [Yingting Li](../../Authors/Yingting_Li.md)
  - [Rishabh Bhardwaj](../../Authors/Rishabh_Bhardwaj.md)
  - [Ambuj Mehrish](../../Authors/Ambuj_Mehrish.md)
  - [Bo Cheng](../../Authors/Bo_Cheng.md)
  - [Soujanya Poria](../../Authors/Soujanya_Poria.md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.04.06 ArXiv v1
  - 更新笔记: 2024.06.06
- 发表:
  - [北京邮电大学](../../Institutions/BUPT_北京邮电大学.md)
  - [新加坡科技设计大学](../../Institutions/SUTD_新加坡科技设计大学.md)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2404.04645)
  - [DOI]()
  - [Github](https://github.com/declare-lab/HyperTTS)
  - [Demo](https://github.com/declare-lab/HyperTTS/tree/master/demo)
- 标签:
  - [语音合成](../../Tags/SpeechSynthesis.md)
  - [开源](../../Tags/OpenSource.md)
- 页数: 12
- 引用: ?
- 被引: ?

</details>

<h2 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h2>
<blockquote>
<p>Neural speech synthesis, or text-to-speech (TTS), aims to transform a signal from the text domain to the speech domain.
While developing TTS architectures that train and test on the same set of speakers has seen significant improvements, out-of-domain speaker performance still faces enormous limitations.
Domain adaptation on a new set of speakers can be achieved by fine-tuning the whole model for each new domain, thus making it parameter-inefficient.
This problem can be solved by Adapters that provide a parameter-efficient alternative to domain adaptation.
Although famous in NLP, speech synthesis has not seen much improvement from Adapters.
In this work, we present <strong>HyperTTS</strong>, which comprises a small learnable network, "hypernetwork", that generates parameters of the Adapter blocks, allowing us to condition Adapters on speaker representations and making them dynamic.
Extensive evaluations of two domain adaptation settings demonstrate its effectiveness in achieving state-of-the-art performance in the parameter-efficient regime.
We also compare different variants of <strong>HyperTTS</strong>, comparing them with baselines in different studies.Promising results on the dynamic adaptation of adapter parameters using hypernetworks open up new avenues for domain-generic multi-speaker TTS systems.
The audio samples and code are available at https://github.com/declare-lab/HyperTTS.</p>
</blockquote>
<p>神经语音合成或文本转语音的目的是将文本域的信号转换为语音域.
虽然开发在相同的说话人集合上进行训练和测试的语音合成架构已经取得了显著的改进, 但对于域外说话人的性能仍然面临着巨大的限制.
这一问题可以通过 Adapter, 一种参数高效的领域自适应来解决.
尽管在自然语言处理中很有名, 但语音合成还没有从 Adapter 中获得太多的改进.
在本文中, 我们提出了 <strong>HyperTTS</strong>, 它由一个小型可学习的网络, "超网络", 生成 Adapter 块的参数, 允许我们根据说话人表示来条件化适配器, 并使其动态.
在两个领域自适应设置的广泛评估中, 我们证明了 <strong>HyperTTS</strong> 在参数高效的情况下取得了最先进的性能.
我们还比较了 <strong>HyperTTS</strong> 的不同变体, 与不同研究中的基线进行了比较.
通过使用超网络来动态适配器参数的可行性, 我们开辟了新的多说话人 TTS 系统的领域通用道路.</p>
<h2 id="1introduction">1.Introduction<a class="headerlink" href="#1introduction" title="Permanent link">&para;</a></h2>
<blockquote>
<p>Neural text-to-speech (TTS) synthesis has trans formed our interactions with digital content by converting text into natural-sounding speech.Cur rent TTS systems are often limited to predefined speaker styles or specific sets of speaker IDs (Ren et al., 2019a), reducing their utility in multi-speaker environments with unseen speakers.
To make TTS scalable and economical, parameter-efficient adaptation of such systems to new speakers is an important, but highly challenging problem (Li et al., 2023b).
Zero-shot and few-shot speaker adaptation techniques (Shen et al., 2023; Li et al., 2023a; Casanova et al., 2021; Cooper et al., 2020; Casanova et al., 2022; Shen et al., 2023) have gained prominence in the domain of TTS, aiming at accommodating new speakers and styles with limited speaker-specific data.
While these methods excel in scenarios with constrained data, it’s important to note that when sufficient data is available, fine-tuning the model offers distinct advantages.
Fine-tuning allows for highly personalized and tailored speech synthesis, precise control over the alignment of synthesized speech with the speaker’s characteristics, and the production of higher-quality, more natural-sounding speech.
In this paper, we assume sufficient availability of data from the adaptation domain.When adapting a multi-speaker TTS model (backbone model) to a target domain, the traditional approach involves complete fine-tuning of the entire back bone (Figure 1-Fine-tuning).However, this approach is resource-intensive, requiring separate copies of model parameters for each new target domain.
To make the adaptation scalable, recent research has introduced parameter-efficient do main adaptation methods using Adapters, as seen in NLP (Houlsby et al., 2019) and speech (Li et al., 2023b).
Adapters incorporate small blocks of learn able dense layers into each block of the backbone model, with the aim of learning additional parameters while keeping the main model parameters fixed (Figure 1-AdapterTTS).
Despite the advantages demonstrated by adapters in various NLP tasks, their direct application in adapting a TTS backbone to a target domain has shown limited improvements (Li et al., 2023b) Since learning a generic TTS system that works well across different speaker styles is a more difficult problem than learning one network per speaker (Ren et al., 2019a, 2021), we hypothesize the same is the case with adapters.
Forcing a static set of adapter parameters to perform well across multiple speakers of the adaptation domain can be challenging and potentially infeasible due to under parameterization (Mehrish et al., 2023a; Biadsy et al., 2022).
In this paper, we present <strong>HyperTTS</strong>, a pioneer ing approach for the parameter-efficient adaptation of TTS models to new speakers.This method conditions adapters on speaker embeddings, expanding the learnable parameter space through a "hypernetwork".
The main highlights of <strong>HyperTTS</strong> are:.
1. Dynamic Adapters: Instead of keeping the adapters static, for each speaker in the adaptation domain, <strong>HyperTTS</strong> learns speaker adaptive adapters.Adapter conditioning on speaker representations is observed to unlock adapter capabilities and make them performant which was a challenge with static adapters (Li et al., 2023b).
2. Parameter Sampling: A large set of speak ers makes it infeasible to keep the space of adapter parameters discrete.
To facilitate this, we employ parameter sampling from a continuous distribution defined by a learnable hyper network.
3. ParameterEfficiency: Compared to parameter-expensive fine-tuning, it achieves competitive results with less than1% of the backbone parameters, making it highly practical and resource-friendly for scalable applications.</p>
<p>We perform a comprehensive set of experiments to showcase <strong>HyperTTS</strong>’s effectiveness (see Figure 1) compared to traditional methods like static bottleneck adapters (AdapterTTS) and full model fine-tuning (TTS-FT).
Our experiments cover datasets from diverse environmental conditions, such as LibriTTS and VCTK, representing various accents from different regions.
Results highlight <strong>HyperTTS</strong>’s parameter-efficient performance advantages over the baselines across both objective and subjective metrics.Notably, <strong>HyperTTS</strong> can even surpass fine-tuning in performance with only a 20% increase in parameters (Table 6-<strong>HyperTTS</strong><sub>e/v/d</sub>).
A key strength of <strong>HyperTTS</strong> lies in its remarkable parameter efficiency: it achieves results within 1 point of fine-tuning while using less than 1% of the parameter count in the backbone.
This practical and resource-friendly approach enables real-world applications.</p>
</blockquote>
<h2 id="2related-work">2.Related Work<a class="headerlink" href="#2related-work" title="Permanent link">&para;</a></h2>
<h3 id="text-to-speech-models">Text-to-Speech Models<a class="headerlink" href="#text-to-speech-models" title="Permanent link">&para;</a></h3>
<blockquote>
<p>The rise of deep learning has transformed TTS technology, with neural network-based architectures like <a href="../../TTS2_Acoustic/2017.03.29_Tacotron/">Tacotron (2017)</a>; <a href="../../Models/TTS2_Acoustic/2017.12.16_Tacotron2.md">Tacotron2 (2017)</a>, <a href="../../TTS2_Acoustic/2020.06.08_FastSpeech2/">FastSpeech2 (2020)</a>, and <a href="../../Models/TTS2_Acoustic/2018.09.19_Transformer_TTS.md">Transformer-TTS (2018)</a> leading the way.
These models represent significant progress in TTS, leveraging deep learning techniques.</p>
<p>Autoregressive TTS models (<a href="../../TTS2_Acoustic/2017.03.29_Tacotron/">Tacotron (2017)</a>; <a href="../../Models/TTS2_Acoustic/2020.05.12_Flowtron.md">Flowtron (2020)</a>; <a href="../../Models/TTS2_Acoustic/2019.05.22_FastSpeech.md">FastSpeech</a>; <a href="../../TTS2_Acoustic/2020.06.08_FastSpeech2/">FastSpeech2 (2020)</a>; <a href="../../TTS2_Acoustic/2020.05.22_Glow-TTS/">Glow-TTS (2020)</a>; <a href="../../Models/TTS2_Acoustic/2020.06.11_FastPitch.md">FastPitch (2020)</a>), while effective, face limitations in maintaining alignment in long utterances and exhibit slower training and inference speeds with longer sequences.</p>
<p>In contrast, non-autoregressive (parallel) models separate phoneme duration estimation from decoding, reducing latency and enhancing training efficiency.
These models typically rely on external aligners or pre-trained autoregressive models for phoneme duration.
To achieve training efficiency and support end-to-end TTS, this paper focuses on a non-autoregressive TTS model with an alignment framework based on the <a href="">RAD-TTS (2022)</a> alignment learning objective.</p>
<p>Recently, several speech models have been compared to GPT in natural language processing, with a focus on in-context learning for speech.
Notably, <a href="../../Speech_LLM/2023.01.05_VALL-E/">VALL-E (2023)</a> and <a href="../../Models/Speech_LLM/2023.02.07_SPEAR-TTS.md">SPEAR-TTS (2023)</a> leverage emerging codecs to learn discrete speech tokens and employ a vocoder-like decodec to convert these tokens into waveforms.
Meanwhile, <a href="../../Models/Speech_LLM/2023.06.23_VoiceBox.md">Voicebox (2023)</a>, inspired by flow-matching and aligned with the <a href="../../Models/TTS2_Acoustic/2019.05.22_FastSpeech.md">FastSpeech (2019)</a> framework, utilizes continuous features like Mel spectrogram and <a href="../../TTS3_Vocoder/2020.10.12_HiFi-GAN/">HiFi-GAN (2020)</a>.</p>
</blockquote>
<h3 id="speaker-adaptation-in-tts">Speaker Adaptation in TTS<a class="headerlink" href="#speaker-adaptation-in-tts" title="Permanent link">&para;</a></h3>
<blockquote>
<p>Speaker adaptation is a crucial aspect of TTS systems, aiming to personalize the synthesized speech by modify ing the voice characteristics to match those of a specific target speaker.
Over the years, various techniques and approaches have been proposed to address the challenges associated with speaker adaptation in TTS (Jia et al., 2018; Chen et al.; Min et al., 2021; Hsieh et al., 2022; Gabry´s et al.2022).
Furthermore, several studies have focused on exploring parameter-efficient methods for adapt ing TTS to new sets of speakers, addressing the need for effective adaptation in diverse speaker scenarios.
These approaches aim to accommodate a wide range of linguistic variations (Pamisetty et al., 2023; Do et al., 2022), including diverse ac cents (Yang et al., 2023), speakers (Luo et al., 2021; Miao et al., 2021; Mehrish et al., 2023a), and low-resource scenarios introduced by the tar get domain (Azizah and Jatmiko, 2022; Mehrish et al., 2023a; Lux and Vu, 2022), while maintain ing the number of trainable parameters.
HYPER TTS primarily focuses on contributing in the line of parameter-efficient domain adaptation of the back bone TTS model to a target set of speakers.</p>
</blockquote>
<h3 id="dynamic-parameters">Dynamic Parameters<a class="headerlink" href="#dynamic-parameters" title="Permanent link">&para;</a></h3>
<blockquote>
<p>Parameter generation, although not popular in speech, has been used in various forms in other domains, such as Klein et al. (2015); Riegler et al. (2015) in NLP and Ha et al. (2017) in computer vision.
Specific to adapters, Bhardwaj et al. (2022); Chen et al. (2020) make prompt tokens dynamic by conditioning their val ues on input text using a parameter prompt generator network, (Üstün et al., 2022; Mahabadi et al., 2021) used hypernetworks for generating adapter down and up-projection weights.
Shared hypernetworks obviate the need to maintain a separate set of parameters for each task (or new setting) and generate weights for each block of the backbone network (Mahabadi et al., 2021).
To the best of our knowledge, this is the first work that studies the utility of a parameter generator in the domain of speech (Mehrish et al., 2023b).</p>
</blockquote>
<h2 id="3methodology">3.Methodology<a class="headerlink" href="#3methodology" title="Permanent link">&para;</a></h2>
<h3 id="31encoder">3.1.Encoder<a class="headerlink" href="#31encoder" title="Permanent link">&para;</a></h3>
<h3 id="32variance-adaptor">3.2.Variance Adaptor<a class="headerlink" href="#32variance-adaptor" title="Permanent link">&para;</a></h3>
<h4 id="duration-predictor">Duration Predictor<a class="headerlink" href="#duration-predictor" title="Permanent link">&para;</a></h4>
<h4 id="pitch-predictor">Pitch Predictor<a class="headerlink" href="#pitch-predictor" title="Permanent link">&para;</a></h4>
<h4 id="energy-predictor">Energy Predictor<a class="headerlink" href="#energy-predictor" title="Permanent link">&para;</a></h4>
<h3 id="33mel-decoder-and-postnet">3.3.Mel-Decoder and Postnet<a class="headerlink" href="#33mel-decoder-and-postnet" title="Permanent link">&para;</a></h3>
<h3 id="34hypernetwork">3.4.Hypernetwork<a class="headerlink" href="#34hypernetwork" title="Permanent link">&para;</a></h3>
<h4 id="implementation">Implementation<a class="headerlink" href="#implementation" title="Permanent link">&para;</a></h4>
<h2 id="4experiments">4.Experiments<a class="headerlink" href="#4experiments" title="Permanent link">&para;</a></h2>
<h3 id="41baseline-models">4.1.Baseline Models<a class="headerlink" href="#41baseline-models" title="Permanent link">&para;</a></h3>
<h4 id="tts-0">TTS-0<a class="headerlink" href="#tts-0" title="Permanent link">&para;</a></h4>
<h4 id="reference-and-reference-voc">Reference and Reference (Voc.)<a class="headerlink" href="#reference-and-reference-voc" title="Permanent link">&para;</a></h4>
<h4 id="tts-ft-full-fine-tuning">TTS-FT (Full Fine-Tuning)<a class="headerlink" href="#tts-ft-full-fine-tuning" title="Permanent link">&para;</a></h4>
<h4 id="adaptertts">AdapterTTS<a class="headerlink" href="#adaptertts" title="Permanent link">&para;</a></h4>
<h4 id="hypertts_1">HyperTTS<a class="headerlink" href="#hypertts_1" title="Permanent link">&para;</a></h4>
<h3 id="42datasets">4.2.Datasets<a class="headerlink" href="#42datasets" title="Permanent link">&para;</a></h3>
<h3 id="43model-configuration">4.3.Model Configuration<a class="headerlink" href="#43model-configuration" title="Permanent link">&para;</a></h3>
<h4 id="backbone-model-pre-training">Backbone Model Pre-training<a class="headerlink" href="#backbone-model-pre-training" title="Permanent link">&para;</a></h4>
<h3 id="44evaluation-metrics">4.4.Evaluation Metrics<a class="headerlink" href="#44evaluation-metrics" title="Permanent link">&para;</a></h3>
<h4 id="objective-metrics">Objective Metrics<a class="headerlink" href="#objective-metrics" title="Permanent link">&para;</a></h4>
<h4 id="subjective-metrics">Subjective Metrics<a class="headerlink" href="#subjective-metrics" title="Permanent link">&para;</a></h4>
<h2 id="5results-discussions">5.Results &amp; Discussions<a class="headerlink" href="#5results-discussions" title="Permanent link">&para;</a></h2>
<h3 id="51subjective-evaluation">5.1.Subjective Evaluation<a class="headerlink" href="#51subjective-evaluation" title="Permanent link">&para;</a></h3>
<h3 id="52impact-of-parameter-efficiency">5.2.Impact of Parameter Efficiency<a class="headerlink" href="#52impact-of-parameter-efficiency" title="Permanent link">&para;</a></h3>
<h3 id="53output-of-hypernetwork">5.3.Output of Hypernetwork<a class="headerlink" href="#53output-of-hypernetwork" title="Permanent link">&para;</a></h3>
<h3 id="54other-discussions">5.4.Other Discussions<a class="headerlink" href="#54other-discussions" title="Permanent link">&para;</a></h3>
<h4 id="layernorms-standard-conditional">Layernorms (Standard &amp; Conditional)<a class="headerlink" href="#layernorms-standard-conditional" title="Permanent link">&para;</a></h4>
<h4 id="low-rank-adaptation">Low-Rank Adaptation<a class="headerlink" href="#low-rank-adaptation" title="Permanent link">&para;</a></h4>
<h2 id="6conclusion">6.Conclusion<a class="headerlink" href="#6conclusion" title="Permanent link">&para;</a></h2>
<blockquote>
<p>In this paper, we present <strong>HyperTTS</strong>, an approach that enhances the effectiveness of adapters by conditioning them on speaker embeddings.
Utilizing a "hypernetwork" to customize adapter block weights for the TTS backbone network, we significantly expand the adapter parameter space.
This dynamic method replaces the conventional static adapter parameter set, enabling input-conditioned parameter sampling.
Additionally, the hypernetwork’s continuous parameter space theoretically allows the generation of adapter parameters for numerous speakers without increasing hypernetwork parameters.
This makes <strong>HyperTTS</strong> an excellent choice for multi-speaker TTS adaptation, surpassing traditional adapter limitations.</p>
<p><strong>Limitations</strong> 
While hypernetworks exhibit promising enhancements in both adaptation domains, there are training challenges to address.
Time and resource constraints may have led to potential underfitting, negatively impacting performance.
Additionally, hypernetworks tend to overfit the backbone model on the adaptation domain, warranting further research to enhance their generalizability.
Notably, the relatively higher number of parameters in hypernetworks poses potential inefficiency for low-resource training.</p>
</blockquote>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.a264c092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4e0fa4ba.min.js"></script>
      
    
  </body>
</html>