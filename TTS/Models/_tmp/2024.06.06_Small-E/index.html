
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.0">
    
    
      
        <title>Small-E - Sapphire Lab</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.9f615399.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#small-e" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Sapphire Lab" class="md-header__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Sapphire Lab
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Small-E
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Sapphire Lab" class="md-nav__button md-logo" aria-label="Sapphire Lab" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Sapphire Lab
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../../PDE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDE
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    Abstract·摘要
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1introduction" class="md-nav__link">
    1.Introduction·引言
  </a>
  
    <nav class="md-nav" aria-label="1.Introduction·引言">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11context-related-works" class="md-nav__link">
    1.1.Context &amp; Related Works
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12linear-surrogate-of-decoder-transformer" class="md-nav__link">
    1.2.Linear Surrogate of Decoder Transformer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13tts-as-a-conditional-codec-language-modeling" class="md-nav__link">
    1.3.TTS as A Conditional Codec Language Modeling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14positioning-contributions" class="md-nav__link">
    1.4.Positioning &amp; Contributions
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2methodology" class="md-nav__link">
    2.Methodology·方法
  </a>
  
    <nav class="md-nav" aria-label="2.Methodology·方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21model-architecture" class="md-nav__link">
    2.1.Model Architecture
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3experiments" class="md-nav__link">
    3.Experiments·实验
  </a>
  
    <nav class="md-nav" aria-label="3.Experiments·实验">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31dataset" class="md-nav__link">
    3.1.Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32implementation-details" class="md-nav__link">
    3.2.Implementation Details
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33benchmark" class="md-nav__link">
    3.3.Benchmark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34methodology" class="md-nav__link">
    3.4.Methodology
  </a>
  
    <nav class="md-nav" aria-label="3.4.Methodology">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#341objective-evaluation" class="md-nav__link">
    3.4.1.Objective Evaluation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#342subjective-evaluation" class="md-nav__link">
    3.4.2.Subjective Evaluation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4results-discussion" class="md-nav__link">
    4.Results &amp; Discussion·结果与讨论
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5conclusion" class="md-nav__link">
    5.Conclusion·结论
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="small-e">Small-E<a class="headerlink" href="#small-e" title="Permanent link">&para;</a></h1>
<details>
<summary>基本信息</summary>

- 标题: Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis
- 作者:
  - 01 [Théodor Lemerle](../../Authors/Théodor_Lemerle.md)
  - 02 [Nicolas Obin](../../Authors/Nicolas_Obin.md)
  - 03 [Axel Roebel](../../Authors/Axel_Roebel.md)
- 机构:
  - [索邦大学](../../Institutions/SorbonneU_法国索邦大学.md)
- 时间:
  - 预印时间: 2024.06.06 ArXiv v1
  - 更新笔记: 2024.06.10
- 发表:
  - [InterSpeech](../../Publications/InterSpeech.md) 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.04467)
  - [DOI]()
  - [Github]()
  - [Demo]()
- 标签:
  - [语言模型](../../Tags/LanguageModel.md)
  - [语音合成](../../Tags/SpeechSynthesis.md)
  - [零样本](../../Tags/Zero-Shot.md)
- 页数: 5
- 引用: 34
- 被引: 0

</details>

<h2 id="abstract">Abstract·摘要<a class="headerlink" href="#abstract" title="Permanent link">&para;</a></h2>
<blockquote>
<p>Recent advancements in text-to-speech (TTS) powered by language models have showcased remarkable capabilities in achieving naturalness and zero-shot voice cloning.
Notably, the decoder-only transformer is the prominent architecture in this domain.
However, transformers face challenges stemming from their quadratic complexity in sequence length, impeding training on lengthy sequences and resource-constrained hardware.
Moreover they lack specific inductive bias with regards to the monotonic nature of TTS alignments.
In response, we propose to replace transformers with emerging recurrent architectures and introduce specialized cross-attention mechanisms for reducing repeating and skipping issues.
Consequently our architecture can be efficiently trained on long samples and achieve state-of-the-art zero-shot voice cloning against baselines of comparable size.</p>
</blockquote>
<h2 id="1introduction">1.Introduction·引言<a class="headerlink" href="#1introduction" title="Permanent link">&para;</a></h2>
<h3 id="11context-related-works">1.1.Context &amp; Related Works<a class="headerlink" href="#11context-related-works" title="Permanent link">&para;</a></h3>
<blockquote>
<p>Over the recent years, neural text-to-speech synthesis (TTS) has gained spectacular improvements in terms of quality with a diversity of approaches and paradigms (<a href="../../Models/TTS2_Acoustic/2019.05.22_FastSpeech.md">FastSpeech</a>, <a href="../../E2E/2021.06.11_VITS/">VITS</a>, <a href="../../Models/Speech_LLM/2023.06.23_VoiceBox.md">VoiceBox</a>, <a href="../Flow/2023.09.10_VoiceFlow.md">VoiceFlow</a>).
In particular, discrete speech and audio representations allowed immediate use of well-established decoder-only transformers such as GPT [5] in many state-of-the-art text-to-audio and text-to-speech model.
However, transformers rely on the self-attention “time-mixing”[6] operation which can be efficiently trained in parallel but suffers from quadratic complexity with respect to the sequence length.
The challenge of designing sequence modeling architecture that can compete with transformers has sparked a resurgence in research on recurrent neural networks (RNNs).
This work introduces the broad term “linear attention” to denote this emerging class of RNNs that replaces self-attention for linear complexity “time-mixing” while keeping performances and high training throughput.</p>
<p>This paper primarily relates to speech models formulated as language models (LMs) or employing discrete audio codecs through Residual Vector Quantization (RVQ).
<a href="../../Speech_LLM/2023.01.05_VALL-E/">VALL-E</a> employs an autoregressive transformer to predict the first quantizer and a parallel transformer for the residuals.
Before the rise of RVQ codecs, Tortoise [8] achieved a significant improvement through scaling up and leveraged a decoder-only transformer to predict a VQ representation of the mel Some other works introduce semantic codes as low frame rate audio latents, following advancements in self-supervised speech representations.
For instance Bark [9] separately predicts semantic codes from text, first quantizers from semantic codes, and residuals with three decoder-only transformers.
<a href="../../Speech_LLM/2023.05.16_SoundStorm/">SoundStorm</a> predicts audio from semantic codes in parallel by leveraging a MaskGit [11] architecture.
In contrast, <a href="../../Diffusion/2023.04.18_NaturalSpeech2/">NaturalSpeech2</a> avoids the language model formulation by learning the continuous latents of an RVQ codec with a diffusion model, sidestepping autoregressive modeling or semantic encoding and instead relying on given durations and fundamental frequency.</p>
</blockquote>
<h3 id="12linear-surrogate-of-decoder-transformer">1.2.Linear Surrogate of Decoder Transformer<a class="headerlink" href="#12linear-surrogate-of-decoder-transformer" title="Permanent link">&para;</a></h3>
<blockquote>
<p>Unlike previous RNNs such as LSTM or GRU, Transformers are significantly faster to train, do not suffer from vanishing gradient and demonstrate scalability with parameters reaching into the hundreds of billions.
Further hardware-aware implementation of self-attention has established it as a prevalent choice for sequence modeling, including applications in audio processing.
General softmax-based attention involves three sequences, denoted as $\mathbf{Q}\in \mathbb{R}^{N\times d}$, $\mathbf{K}\in \mathbb{R}^{N'\times d}$, and $\mathbf{V}\in \mathbb{R}^{N'\times d'}$, along with an optional mask $\mathbf{M}\in \mathbb{R}^{N\times N'}$.
The attention function in defined as:</p>
</blockquote>
<p>$$
  Attention(\mathbf{Q},\mathbf{K},\mathbf{V}) = \text{softmax}(\dfrac{\mathbb{Q}\mathbb{K}^{\mathsf{T}}}{\sqrt{d}}\odot\mathbf{M})\mathbf{V}.\tag{01}
$$</p>
<blockquote>
<p>When $\mathbf{Q}$, $\mathbf{K}$, and $\mathbf{V}$ represent different linear projections of the same input sequence $\mathbf{X}\in \mathbb{R}^{N\times d}$ (and are therefore function of $\mathbf{X}$), the resulting function $\mathbf{X}\mapsto Attention(\mathbf{Q},\mathbf{K},\mathbf{V})$ is referred to as self-attention.
Backing the success of GPT-2 [5] and successors for natural language modeling, the decoder-only Transformer architecture can be generalized with the terminology proposed in [6]:</p>
</blockquote>
<p>$$</p>
<p>$$</p>
<h3 id="13tts-as-a-conditional-codec-language-modeling">1.3.TTS as A Conditional Codec Language Modeling<a class="headerlink" href="#13tts-as-a-conditional-codec-language-modeling" title="Permanent link">&para;</a></h3>
<h3 id="14positioning-contributions">1.4.Positioning &amp; Contributions<a class="headerlink" href="#14positioning-contributions" title="Permanent link">&para;</a></h3>
<h2 id="2methodology">2.Methodology·方法<a class="headerlink" href="#2methodology" title="Permanent link">&para;</a></h2>
<h3 id="21model-architecture">2.1.Model Architecture<a class="headerlink" href="#21model-architecture" title="Permanent link">&para;</a></h3>
<h2 id="3experiments">3.Experiments·实验<a class="headerlink" href="#3experiments" title="Permanent link">&para;</a></h2>
<h3 id="31dataset">3.1.Dataset<a class="headerlink" href="#31dataset" title="Permanent link">&para;</a></h3>
<h3 id="32implementation-details">3.2.Implementation Details<a class="headerlink" href="#32implementation-details" title="Permanent link">&para;</a></h3>
<h3 id="33benchmark">3.3.Benchmark<a class="headerlink" href="#33benchmark" title="Permanent link">&para;</a></h3>
<h3 id="34methodology">3.4.Methodology<a class="headerlink" href="#34methodology" title="Permanent link">&para;</a></h3>
<h4 id="341objective-evaluation">3.4.1.Objective Evaluation<a class="headerlink" href="#341objective-evaluation" title="Permanent link">&para;</a></h4>
<h4 id="342subjective-evaluation">3.4.2.Subjective Evaluation<a class="headerlink" href="#342subjective-evaluation" title="Permanent link">&para;</a></h4>
<h2 id="4results-discussion">4.Results &amp; Discussion·结果与讨论<a class="headerlink" href="#4results-discussion" title="Permanent link">&para;</a></h2>
<h2 id="5conclusion">5.Conclusion·结论<a class="headerlink" href="#5conclusion" title="Permanent link">&para;</a></h2>
<blockquote>
<p>In this paper we presented Small-E, a TTS model based on codec language model.
The proposed model tackles limitations of current LM TTS models.
Firstly, we introduced Linear Causal Language Model in place of the traditional decoder-only transformer.
Secondly, we introduced a cross-attention mechanism designed specifically to handle text and speech modalities in the context of TTS, with the idea of preventing the skip and repetition problem of auto-regressive models.
In contrast with existing work, we were able to show that training LM TTS model is interesting even on limited hardware and leads to state-of-the-art quality against model of the same size.
Experimental evaluation demonstrated the efficiency of the proposed model either in terms of training throughput, skip and repetition reduction, as well as naturalness and similarity These to the reference speaker of the generated speech. observations constitute encouraging results opening the way for small and efficient generative TTS models.
In future work we are interested in streaming TTS, taking advantage of the linear complexity of LCLM for very long or embedded synthesis.</p>
</blockquote>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.a264c092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4e0fa4ba.min.js"></script>
      
    
  </body>
</html>